
Scripts and aliases for Hadoop development.


Installing the scripts

   Add something like the following to your bashrc:

   export HDEV=/home/eli/src/play/hadoop-dev
   . $HDEV/bin/hadoop-alias.sh
   export PATH=$HDEV/bin:$HDEV/test:$PATH

   Edit HADOOP_SRC_ROOT in $HDEV/bin/hadoop-home.sh to point to
   the root directory where you keep your source trees.


Run Hadoop daemons

    nn1    Run the namenode daemon out of the first tree
    dn1    " datanode
    jt1    " jobtracker
    tt1    " tasktracker


Execute Hadoop commands

    format-namenode 1

    hadoop1 fs -put temp temp0

    hadoop1 dfsadmin -safemode leave

    . $HDEV/bin/hadoop-home.sh 1
    J=$HADOOP_MAPRED_HOME/build/hadoop-mapred-examples-0.23.0-SNAPSHOT.jar
    hadoop1 jar $J pi 2 100000


Execute a specific unit test

    ant-test-core TestFoo
    ant-test-core20 TestFoo
    ant-test-contrib20 TestFoo
    ant-test-hdfs TestFoo
    ant-test-mr TestFoo

    The following will loop the test until it fails:

    loop-core-test TestFoo
    loop-core20-test TestFoo
    loop-hdfs-test TestFoo
    loop-mr-test TestFoo


Development

    Test-patch:    ant-test-patch ~/hadoop-x.patch >& ~/test.out
    Release audit: ant-releaseaudit


Subversion

    Revert revision r:  svn_revert r

    Merge revision r to a release branch:

    svn_merge_common r HADOOP-XYZ
    svn_merge_hdfs r HDFS-XYX
    svn_merge_mapreduce r MAPREDUCE-XYZ
